{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "from tweepy import OAuthHandler\n",
    "from tweepy import Stream\n",
    "from tweepy.streaming import StreamListener\n",
    "import json\n",
    "import jsonpickle\n",
    "from datetime import datetime, date, time, timedelta\n",
    "\n",
    "#Variables that contains the user credentials to access Twitter API\n",
    "access_token = \"4411474994-3fGhUuDAvjL1X5SBoat5fA7nTCNuf0t4lsjpaUE\"\n",
    "access_token_secret = \"JMoaE8YUXLR7yQqplHipzr07xW0Bhb2iYe46NkHwYRVAJ\"\n",
    "consumer_key = \"uAk8Uas7X9JUh3DNTpNIxd5OX\"\n",
    "consumer_secret = \"MYfrcCuGerViS8zMzHQZeSwEfa3Nd00x9dvd1N1AZZNLYQ2boW\"\n",
    "\n",
    "auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading max 50000 tweets\n",
      "Downloaded 100 tweets\n",
      "Downloaded 200 tweets\n",
      "Downloaded 300 tweets\n",
      "Downloaded 400 tweets\n",
      "Downloaded 500 tweets\n",
      "Downloaded 600 tweets\n",
      "Downloaded 700 tweets\n",
      "Downloaded 800 tweets\n",
      "Downloaded 900 tweets\n",
      "Downloaded 1000 tweets\n",
      "Downloaded 1100 tweets\n",
      "Downloaded 1200 tweets\n",
      "Downloaded 1300 tweets\n",
      "Downloaded 1400 tweets\n",
      "Downloaded 1500 tweets\n",
      "Downloaded 1600 tweets\n",
      "Downloaded 1700 tweets\n",
      "Downloaded 1800 tweets\n",
      "Downloaded 1900 tweets\n",
      "Downloaded 1985 tweets\n",
      "Downloaded 2085 tweets\n",
      "Downloaded 2185 tweets\n",
      "Downloaded 2285 tweets\n",
      "Downloaded 2374 tweets\n",
      "Downloaded 2474 tweets\n",
      "Downloaded 2574 tweets\n",
      "Downloaded 2674 tweets\n",
      "Downloaded 2774 tweets\n",
      "Downloaded 2874 tweets\n",
      "Downloaded 2974 tweets\n",
      "Downloaded 3074 tweets\n",
      "Downloaded 3174 tweets\n",
      "Downloaded 3274 tweets\n",
      "Downloaded 3374 tweets\n",
      "Downloaded 3474 tweets\n",
      "Downloaded 3574 tweets\n",
      "Downloaded 3674 tweets\n",
      "Downloaded 3774 tweets\n",
      "Downloaded 3874 tweets\n",
      "Downloaded 3974 tweets\n",
      "Downloaded 4074 tweets\n",
      "Downloaded 4174 tweets\n",
      "Downloaded 4274 tweets\n",
      "Downloaded 4374 tweets\n",
      "Downloaded 4474 tweets\n",
      "Downloaded 4568 tweets\n",
      "Downloaded 4668 tweets\n",
      "Downloaded 4764 tweets\n",
      "Downloaded 4855 tweets\n",
      "Downloaded 4955 tweets\n",
      "Downloaded 5055 tweets\n",
      "Downloaded 5155 tweets\n",
      "Downloaded 5255 tweets\n",
      "Downloaded 5355 tweets\n",
      "Downloaded 5455 tweets\n",
      "Downloaded 5555 tweets\n",
      "Downloaded 5655 tweets\n",
      "Downloaded 5755 tweets\n",
      "Downloaded 5855 tweets\n",
      "Downloaded 5955 tweets\n",
      "Downloaded 6055 tweets\n",
      "Downloaded 6155 tweets\n",
      "Downloaded 6255 tweets\n",
      "Downloaded 6355 tweets\n",
      "Downloaded 6455 tweets\n",
      "Downloaded 6555 tweets\n",
      "Downloaded 6655 tweets\n",
      "Downloaded 6755 tweets\n",
      "Downloaded 6855 tweets\n",
      "Downloaded 6955 tweets\n",
      "Downloaded 7044 tweets\n",
      "Downloaded 7143 tweets\n",
      "Downloaded 7243 tweets\n",
      "Downloaded 7343 tweets\n",
      "Downloaded 7443 tweets\n",
      "Downloaded 7543 tweets\n",
      "Downloaded 7643 tweets\n",
      "Downloaded 7743 tweets\n",
      "Downloaded 7843 tweets\n",
      "Downloaded 7943 tweets\n",
      "Downloaded 8043 tweets\n",
      "Downloaded 8143 tweets\n",
      "Downloaded 8243 tweets\n",
      "Downloaded 8343 tweets\n",
      "Downloaded 8443 tweets\n",
      "Downloaded 8543 tweets\n",
      "Downloaded 8643 tweets\n",
      "Downloaded 8743 tweets\n",
      "Downloaded 8843 tweets\n",
      "Downloaded 8943 tweets\n",
      "Downloaded 9043 tweets\n",
      "Downloaded 9143 tweets\n",
      "Downloaded 9243 tweets\n",
      "Downloaded 9343 tweets\n",
      "Downloaded 9443 tweets\n",
      "Downloaded 9543 tweets\n",
      "Downloaded 9643 tweets\n",
      "Downloaded 9743 tweets\n",
      "Downloaded 9843 tweets\n",
      "Downloaded 9943 tweets\n",
      "Downloaded 10043 tweets\n",
      "Downloaded 10143 tweets\n",
      "Downloaded 10243 tweets\n",
      "Downloaded 10343 tweets\n",
      "Downloaded 10443 tweets\n",
      "Downloaded 10543 tweets\n",
      "Downloaded 10643 tweets\n",
      "Downloaded 10743 tweets\n",
      "Downloaded 10843 tweets\n",
      "Downloaded 10943 tweets\n",
      "Downloaded 11043 tweets\n",
      "Downloaded 11143 tweets\n",
      "Downloaded 11243 tweets\n",
      "Downloaded 11343 tweets\n",
      "Downloaded 11443 tweets\n",
      "Downloaded 11543 tweets\n",
      "Downloaded 11643 tweets\n",
      "Downloaded 11743 tweets\n",
      "Downloaded 11843 tweets\n",
      "Downloaded 11943 tweets\n",
      "Downloaded 12043 tweets\n",
      "Downloaded 12143 tweets\n",
      "Downloaded 12243 tweets\n",
      "Downloaded 12343 tweets\n",
      "Downloaded 12443 tweets\n",
      "Downloaded 12543 tweets\n",
      "Downloaded 12643 tweets\n",
      "Downloaded 12743 tweets\n",
      "Downloaded 12843 tweets\n",
      "Downloaded 12943 tweets\n",
      "Downloaded 13043 tweets\n",
      "Downloaded 13143 tweets\n",
      "Downloaded 13243 tweets\n",
      "Downloaded 13343 tweets\n",
      "Downloaded 13443 tweets\n",
      "Downloaded 13543 tweets\n",
      "Downloaded 13643 tweets\n",
      "Downloaded 13739 tweets\n",
      "Downloaded 13839 tweets\n",
      "Downloaded 13939 tweets\n",
      "Downloaded 14039 tweets\n",
      "Downloaded 14139 tweets\n",
      "Downloaded 14239 tweets\n",
      "Downloaded 14339 tweets\n",
      "Downloaded 14439 tweets\n",
      "Downloaded 14539 tweets\n",
      "Downloaded 14639 tweets\n",
      "Downloaded 14733 tweets\n",
      "Downloaded 14833 tweets\n",
      "Downloaded 14933 tweets\n",
      "Downloaded 15033 tweets\n",
      "Downloaded 15133 tweets\n",
      "Downloaded 15233 tweets\n",
      "Downloaded 15333 tweets\n",
      "Downloaded 15433 tweets\n",
      "Downloaded 15533 tweets\n",
      "Downloaded 15633 tweets\n",
      "Downloaded 15733 tweets\n",
      "Downloaded 15833 tweets\n",
      "Downloaded 15933 tweets\n",
      "Downloaded 16033 tweets\n",
      "Downloaded 16133 tweets\n",
      "Downloaded 16233 tweets\n",
      "Downloaded 16333 tweets\n",
      "Downloaded 16433 tweets\n",
      "Downloaded 16533 tweets\n",
      "Downloaded 16633 tweets\n",
      "Downloaded 16733 tweets\n",
      "Downloaded 16833 tweets\n",
      "Downloaded 16933 tweets\n",
      "Downloaded 17033 tweets\n",
      "Downloaded 17133 tweets\n",
      "Downloaded 17233 tweets\n",
      "Downloaded 17333 tweets\n",
      "Downloaded 17433 tweets\n",
      "Downloaded 17533 tweets\n",
      "Downloaded 17633 tweets\n",
      "Downloaded 17733 tweets\n",
      "Downloaded 17833 tweets\n",
      "Downloaded 17933 tweets\n",
      "Rate limit reached. Sleeping for: 383\n",
      "Downloaded 18033 tweets\n",
      "Downloaded 18133 tweets\n",
      "Downloaded 18233 tweets\n",
      "Downloaded 18333 tweets\n",
      "Downloaded 18433 tweets\n",
      "Downloaded 18533 tweets\n",
      "Downloaded 18633 tweets\n",
      "Downloaded 18733 tweets\n",
      "Downloaded 18833 tweets\n",
      "Downloaded 18933 tweets\n",
      "Downloaded 19033 tweets\n",
      "Downloaded 19133 tweets\n",
      "Downloaded 19233 tweets\n",
      "Downloaded 19333 tweets\n",
      "Downloaded 19433 tweets\n",
      "Downloaded 19533 tweets\n",
      "Downloaded 19633 tweets\n",
      "Downloaded 19733 tweets\n",
      "Downloaded 19833 tweets\n",
      "Downloaded 19933 tweets\n",
      "Downloaded 20033 tweets\n",
      "Downloaded 20133 tweets\n",
      "Downloaded 20233 tweets\n",
      "Downloaded 20333 tweets\n",
      "Downloaded 20433 tweets\n",
      "Downloaded 20533 tweets\n",
      "Downloaded 20633 tweets\n",
      "Downloaded 20733 tweets\n",
      "Downloaded 20833 tweets\n",
      "Downloaded 20931 tweets\n",
      "Downloaded 21023 tweets\n",
      "Downloaded 21123 tweets\n",
      "Downloaded 21223 tweets\n",
      "Downloaded 21323 tweets\n",
      "Downloaded 21419 tweets\n",
      "Downloaded 21519 tweets\n",
      "Downloaded 21619 tweets\n",
      "Downloaded 21719 tweets\n",
      "Downloaded 21819 tweets\n",
      "Downloaded 21919 tweets\n",
      "Downloaded 22019 tweets\n",
      "Downloaded 22119 tweets\n",
      "Downloaded 22219 tweets\n",
      "Downloaded 22319 tweets\n",
      "Downloaded 22419 tweets\n",
      "Downloaded 22519 tweets\n",
      "Downloaded 22619 tweets\n",
      "Downloaded 22719 tweets\n",
      "Downloaded 22819 tweets\n",
      "Downloaded 22919 tweets\n",
      "Downloaded 23019 tweets\n",
      "Downloaded 23119 tweets\n",
      "Downloaded 23219 tweets\n",
      "Downloaded 23319 tweets\n",
      "Downloaded 23419 tweets\n",
      "Downloaded 23519 tweets\n",
      "Downloaded 23619 tweets\n",
      "Downloaded 23719 tweets\n",
      "Downloaded 23819 tweets\n",
      "Downloaded 23919 tweets\n",
      "Downloaded 24019 tweets\n",
      "Downloaded 24119 tweets\n",
      "Downloaded 24219 tweets\n",
      "Downloaded 24319 tweets\n",
      "Downloaded 24419 tweets\n",
      "Downloaded 24519 tweets\n",
      "Downloaded 24619 tweets\n",
      "Downloaded 24719 tweets\n",
      "Downloaded 24819 tweets\n",
      "Downloaded 24919 tweets\n",
      "Downloaded 25019 tweets\n",
      "Downloaded 25119 tweets\n",
      "Downloaded 25219 tweets\n",
      "Downloaded 25319 tweets\n",
      "Downloaded 25419 tweets\n",
      "Downloaded 25519 tweets\n",
      "Downloaded 25619 tweets\n",
      "Downloaded 25719 tweets\n",
      "Downloaded 25819 tweets\n",
      "Downloaded 25919 tweets\n",
      "Downloaded 26019 tweets\n",
      "Downloaded 26119 tweets\n",
      "Downloaded 26219 tweets\n",
      "Downloaded 26319 tweets\n",
      "Downloaded 26419 tweets\n",
      "Downloaded 26519 tweets\n",
      "Downloaded 26619 tweets\n",
      "Downloaded 26719 tweets\n",
      "Downloaded 26819 tweets\n",
      "Downloaded 26919 tweets\n",
      "Downloaded 27019 tweets\n",
      "Downloaded 27119 tweets\n",
      "Downloaded 27219 tweets\n",
      "Downloaded 27319 tweets\n",
      "Downloaded 27419 tweets\n",
      "Downloaded 27519 tweets\n",
      "Downloaded 27619 tweets\n",
      "Downloaded 27719 tweets\n",
      "Downloaded 27819 tweets\n",
      "Downloaded 27919 tweets\n",
      "Downloaded 28019 tweets\n",
      "Downloaded 28119 tweets\n",
      "Downloaded 28219 tweets\n",
      "Downloaded 28319 tweets\n",
      "Downloaded 28419 tweets\n",
      "Downloaded 28519 tweets\n",
      "Downloaded 28619 tweets\n",
      "Downloaded 28719 tweets\n",
      "Downloaded 28819 tweets\n",
      "Downloaded 28919 tweets\n",
      "Downloaded 29019 tweets\n",
      "Downloaded 29119 tweets\n",
      "Downloaded 29219 tweets\n",
      "Downloaded 29319 tweets\n",
      "Downloaded 29419 tweets\n",
      "Downloaded 29519 tweets\n",
      "Downloaded 29619 tweets\n",
      "Downloaded 29719 tweets\n",
      "Downloaded 29819 tweets\n",
      "Downloaded 29919 tweets\n",
      "Downloaded 30019 tweets\n",
      "Downloaded 30119 tweets\n",
      "Downloaded 30219 tweets\n",
      "Downloaded 30319 tweets\n",
      "Downloaded 30419 tweets\n",
      "Downloaded 30519 tweets\n",
      "Downloaded 30619 tweets\n",
      "Downloaded 30719 tweets\n",
      "Downloaded 30819 tweets\n",
      "Downloaded 30919 tweets\n",
      "Downloaded 31019 tweets\n",
      "Downloaded 31119 tweets\n",
      "Downloaded 31219 tweets\n",
      "Downloaded 31319 tweets\n",
      "Downloaded 31419 tweets\n",
      "Downloaded 31519 tweets\n",
      "Downloaded 31619 tweets\n",
      "Downloaded 31719 tweets\n",
      "Downloaded 31819 tweets\n",
      "Downloaded 31919 tweets\n",
      "Downloaded 32019 tweets\n",
      "Downloaded 32119 tweets\n",
      "Downloaded 32219 tweets\n",
      "Downloaded 32319 tweets\n",
      "Downloaded 32419 tweets\n",
      "Downloaded 32519 tweets\n",
      "Downloaded 32619 tweets\n",
      "Downloaded 32719 tweets\n",
      "Downloaded 32819 tweets\n",
      "Downloaded 32919 tweets\n",
      "Downloaded 33019 tweets\n",
      "Downloaded 33119 tweets\n",
      "Downloaded 33219 tweets\n",
      "Downloaded 33319 tweets\n",
      "Downloaded 33419 tweets\n",
      "Downloaded 33519 tweets\n",
      "Downloaded 33619 tweets\n",
      "Downloaded 33719 tweets\n",
      "Downloaded 33819 tweets\n",
      "Downloaded 33919 tweets\n",
      "Downloaded 34019 tweets\n",
      "Downloaded 34119 tweets\n",
      "Downloaded 34219 tweets\n",
      "Downloaded 34319 tweets\n",
      "Downloaded 34419 tweets\n",
      "Downloaded 34519 tweets\n",
      "Downloaded 34619 tweets\n",
      "Downloaded 34719 tweets\n",
      "Downloaded 34819 tweets\n",
      "Downloaded 34919 tweets\n",
      "Downloaded 35019 tweets\n",
      "Downloaded 35119 tweets\n",
      "Downloaded 35219 tweets\n",
      "Downloaded 35319 tweets\n",
      "Downloaded 35419 tweets\n",
      "Downloaded 35519 tweets\n",
      "Downloaded 35619 tweets\n",
      "Downloaded 35719 tweets\n",
      "Downloaded 35819 tweets\n",
      "Downloaded 35919 tweets\n",
      "Rate limit reached. Sleeping for: 464\n",
      "Downloaded 36019 tweets\n",
      "Downloaded 36020 tweets\n",
      "No more tweets found\n",
      "Downloaded 36020 tweets, Saved to <_io.TextIOWrapper name='data/dominos_50k.json' mode='w' encoding='cp1252'>\n"
     ]
    }
   ],
   "source": [
    "def userorbrandReferences():\n",
    "\n",
    "    startDate = datetime(2019, 12, 1, 0, 0, 0) #The date contains year, month, day, hour\n",
    "    endDate = datetime(2019, 12, 20, 0, 0, 0)\n",
    "   \n",
    "    #RECENT TWEETS-SEARCH API\n",
    "    fName = \"data/dominos_50k.json\"    #filename\n",
    "    searchQuery = \"dominos -filter:retweets\" #query - keywords/hashtag\n",
    "    maxTweets = 50000 #maximum tweets\n",
    "    tweetsPerQry = 100 #tweets / batch\n",
    "\n",
    "    sinceId = None\n",
    "    max_id = -1\n",
    "\n",
    "    tweetCount = 0\n",
    "    print(\"Downloading max {0} tweets\".format(maxTweets))\n",
    "    with open(fName, 'w') as f:\n",
    "        while tweetCount < maxTweets:\n",
    "            try:\n",
    "                if (max_id <= 0):\n",
    "                    if (not sinceId):\n",
    "                        new_tweets = api.search(q=searchQuery, count=tweetsPerQry, tweet_mode='extended')\n",
    "                    else:\n",
    "                        new_tweets = api.search(q=searchQuery, count=tweetsPerQry, tweet_mode='extended',\n",
    "                                                since_id=sinceId)\n",
    "                else:\n",
    "                    if (not sinceId):\n",
    "                        new_tweets = api.search(q=searchQuery, count=tweetsPerQry, tweet_mode='extended',\n",
    "                                                max_id=str(max_id - 1))\n",
    "                    else:\n",
    "                        new_tweets = api.search(q=searchQuery, count=tweetsPerQry, tweet_mode='extended',\n",
    "                                                max_id=str(max_id - 1),\n",
    "                                                since_id=sinceId)\n",
    "                if not new_tweets:\n",
    "                    print(\"No more tweets found\")\n",
    "                    break\n",
    "                for tweet in new_tweets:\n",
    "                    f.write(json.dumps(tweet._json)+\"\\n\")\n",
    "\n",
    "                tweetCount += len(new_tweets)\n",
    "                print(\"Downloaded {0} tweets\".format(tweetCount))\n",
    "                max_id = new_tweets[-1].id\n",
    "            except tweepy.TweepError as e:\n",
    "                # Just exit if any error\n",
    "                print(\"some error : \" + str(e))\n",
    "                break\n",
    "            #break\n",
    "\n",
    "    print (\"Downloaded {0} tweets, Saved to {1}\".format(tweetCount, f))\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    userorbrandReferences()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tweets' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-ced801dfe64f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mwriter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mwriter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriterow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'tweets'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'create_at'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mtweet\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtweets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[0mwriter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriterow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtweet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtweet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdate\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tweets' is not defined"
     ]
    }
   ],
   "source": [
    "import GetOldTweets3 as got\n",
    "import csv\n",
    "\n",
    "text_query = 'pizza -filter:retweets'\n",
    "since_date = '2020-02-11'\n",
    "until_date = '2020-02-22'\n",
    "count = 100000\n",
    "# Creation of query object\n",
    "#tweetCriteria = got.manager.TweetCriteria().setQuerySearch(text_query).setSince(since_date).setUntil(until_date).setLang('eng').setMaxTweets(count)\n",
    "# Creation of list that contains all tweets\n",
    "#tweets = got.manager.TweetManager.getTweets(tweetCriteria)\n",
    "# Creating list of chosen tweet data\n",
    "#text_tweets = [[tweet.date, tweet.text] for tweet in tweets]\n",
    "\n",
    "with open('data/pizza_2.csv', 'a', encoding=\"utf-8\", newline = '') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['tweets', 'create_at'])\n",
    "    for tweet in tweets:\n",
    "        writer.writerow([tweet.text, tweet.date])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "screen_name = \"pizzahut\" #enter screen name on who you would like to check on it.\n",
    "fname = \"data/{}_profile.json\".format(screen_name)\n",
    "with open(fname, 'w') as f:\n",
    "    profile = api.get_user(screen_name=screen_name)        \n",
    "    f.write(json.dumps(profile._json, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "from sumy.summarizers.text_rank import TextRankSummarizer\n",
    "\"\"\"from .parsers.plaintext import PlaintextParser\n",
    "from .summarizers.luhn import LuhnSummarizer\n",
    "from .summarizers.edmundson import EdmundsonSummarizer\n",
    "from .summarizers.lsa import LsaSummarizer\n",
    "from .summarizers.text_rank import TextRankSummarizer\n",
    "from .summarizers.lex_rank import LexRankSummarizer\n",
    "from .summarizers.sum_basic import SumBasicSummarizer\n",
    "from .summarizers.kl import KLSummarizer\"\"\"\n",
    "\n",
    "#English text only\n",
    "file = \"1.txt\" \n",
    "\n",
    "parser = PlaintextParser.from_file(file, Tokenizer(\"english\"))\n",
    "\n",
    "summarizer = TextRankSummarizer()\n",
    "summary = summarizer(parser.document, 3) #Summarize the document in ??? sentences ?? = how many sentences u want to be written to u \n",
    "for sentence in summary:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt; plt.rcdefaults()\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def get_mentions(tweet):\n",
    "    entities = tweet.get('entities', {})\n",
    "    mentions = entities.get('user_mentions', [])\n",
    "    return [tag['screen_name'] for tag in mentions]\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    screen_name = \"pizzahutmsia\" #note: if the user_timeline.json file does not exist, run getuserTimeline\n",
    "    timeline_dominos = 'data/user_timeline_dominosMY_limit.json'\n",
    "    timeline_pizzahut = 'data/user_timeline_pizzahutmsia_limit.json'\n",
    "    dominos = []\n",
    "    pizzahut = []\n",
    "    d_users = Counter()\n",
    "    p_users = Counter()\n",
    "    \n",
    "    with open(timeline_dominos) as f1, open(timeline_pizzahut) as f2:\n",
    "        rt = 0\n",
    "        fav = 0\n",
    "        curfav = 0\n",
    "        currt = 0\n",
    "        mention = 0\n",
    "        for line in f1:\n",
    "            tweet = json.loads(line)\n",
    "            if tweet['favorite_count'] != 0:\n",
    "                curfav = tweet['favorite_count']\n",
    "                fav = fav + curfav\n",
    "            if tweet['retweet_count'] != 0:\n",
    "                currt = tweet['retweet_count']\n",
    "                rt = rt + currt\n",
    "            mentions_in_tweet = get_mentions(tweet)\n",
    "            d_users.update(mentions_in_tweet)\n",
    "        for user, count in d_users.most_common():\n",
    "            print(\"{}: {}\".format(user, count))\n",
    "            mention = mention + count\n",
    "        \n",
    "        dominos.append(mention)\n",
    "        dominos.append(rt)\n",
    "        dominos.append(fav)\n",
    "\n",
    "        print(\"PizzahutMsia\")\n",
    "        rt = 0\n",
    "        fav = 0\n",
    "        curfav = 0\n",
    "        currt = 0\n",
    "        mention = 0\n",
    "        for line in f2:\n",
    "            tweet = json.loads(line)\n",
    "            if tweet['favorite_count'] != 0:\n",
    "                curfav = tweet['favorite_count']\n",
    "                fav = fav + curfav\n",
    "            if tweet['retweet_count'] != 0:\n",
    "                currt = tweet['retweet_count']\n",
    "                rt = rt + currt\n",
    "            mentions_in_tweet = get_mentions(tweet)\n",
    "            p_users.update(mentions_in_tweet)\n",
    "        for user, count in p_users.most_common():\n",
    "            print(\"{}: {}\".format(user, count))\n",
    "            mention = mention + count\n",
    "        \n",
    "        pizzahut.append(mention)\n",
    "        pizzahut.append(rt)\n",
    "        pizzahut.append(fav)\n",
    "\n",
    "        #print(dominos, pizzahut)\n",
    "        '''\n",
    "        index = np.arange(3)\n",
    "        bar_width = 0.35\n",
    "        opacity = 0.8\n",
    "\n",
    "        rects1 = plt.bar(index, dominos, bar_width, alpha=opacity, color='b', label='DominosMY')       \n",
    "        rects2 = plt.bar(index+bar_width, pizzahut, bar_width, alpha=opacity, color='r', label='PizzahutMsia')\n",
    "\n",
    "        plt.xlabel('Metrics')\n",
    "        plt.ylabel('Amount')\n",
    "        plt.title('Engagement Analysis')\n",
    "        plt.xticks(index, ('Mentions', 'Retweets', 'Likes'))\n",
    "        plt.legend()\n",
    "\n",
    "        plt.tight_layout()\n",
    "        autolabel_v(rects1)\n",
    "        autolabel_v(rects2)\n",
    "        plt.show()\n",
    "\n",
    "        ### ENGAGEMENTS ###\n",
    "        eng_dominos = dominos[0] + dominos[1] + dominos[2]\n",
    "        eng_pizzahut = pizzahut[0] + pizzahut[1] + pizzahut[2]\n",
    "        eng = [eng_dominos, eng_pizzahut]\n",
    "        \n",
    "        rects1 = plt.bar(np.arange(2), eng, bar_width, alpha=opacity, color=['b','r'])       \n",
    "        #rects2 = plt.bar(index+bar_width, eng_pizzahut, bar_width, alpha=opacity, color='r', label='PizzahutMsia')\n",
    "\n",
    "        plt.xlabel('Entities')\n",
    "        plt.ylabel('Amount')\n",
    "        plt.title('Total Engagements')\n",
    "        plt.xticks(index, ('DominosMY', 'PizzahutMsia'))\n",
    "        plt.show()\n",
    "        '''"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
